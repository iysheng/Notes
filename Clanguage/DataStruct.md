
### libevent 代码阅读笔记
1. 数据结构 tailqueue
2. 数据结构 list
3. gnu gcc 的 attribute 属性，标记函数属性的时候，添加到函数的最开始，结构体的最末尾！！！
``` C
/*
 * __attribute__ ((unused)) 属性标记这个函数极有可能不会调用，告诉 gcc 不要打警告
 */
__attribute__ ((unused)) int funca(void)
{
    return 0;
}

/*
 * __attribute__((packed)) 属性标记这个结构体具有打包属性，纵使这个结构体没有实际的 pack 效果，也不要打警告
 */
struct foo {
int x;
char a, b, c, d;
} __attribute__((packed));
```
4. inline 关键字修改函数定义
```C
inline void func(void)
{

}
```
5. (void)x; /* 可以避免编译器的警告未使用的变量 */
6. #pragma pack(n) 可以修改 alignment
7. crt0.o 是连接到C程序的一段启动函数集合。这里一般做一些程序 main 程序之前的准备工作。crt（C runtime）,0 表示最开始。这个.o一般由一段汇编语言编译而来。比如在这里会执行一些 C++ 的初始构造函数。
8. 宏定义中的 # 和 ## 符号，# 表示字符串化， ## 表示连词符号，特别地针对 ##，如果有连词符之前有 . 符号，那么可以省去 ## 符号。因为 ## 连词符号的意思是连接前面的字母组成新的长字母
9. 在 gcc 中使用 asm 内联汇编的方法: __asm__("nop");
10. ATPCS 标准规定，在 C 语言函数调用时，r0,r1,r2,r3 作为参数进行传递，所以用汇编写的函数可以放心地使用r0-r3,但是如果想要使用 r4-r11 ，这时候就要小心点了，如果在调用该汇编函数的 C 函数中没有使用到 r4-r11 还好说，如果使用到了，那么很可能程序就会出问题，所以啊，如果你用汇编写的函数使用到了 r4-r11 这些寄存器，使用之前先 push {r4,,,,} 以下，在函数的末尾在 pop {r4,,,,} 出来比较安全
11. 可变参数的处理, va_start va_arg va_end 这些都是一些宏定义, 展开可以逐个将可变参数列表给提取出来
* #define va_start(list,param1)   ( list = (va_list)&param1+ sizeof(param1) )
* #define va_arg(list,mode)   ( (mode *) ( list += sizeof(mode) ) )[-1]
* #define va_end(list) ( list = (va_list)0 )
* 可变参数的宏 __VA_ARGS__  表示 ... 这个可变参数
```C
/* 示例程序 ... 表示可变参数 */
void simple_va_fun(int i, ...)
{
    va_list arg_ptr;
    int j=0;

    宏展开，定义 arg_ptr, 指向第一个可变参数
    va_start(arg_ptr, i);
    宏展开，获取第一个可变参数的值
    j=va_arg(arg_ptr, int);
    宏展开，结束展开,取消 arg_ptr 初始化，设置为 0
    va_end(arg_ptr);
    printf("%d %d\n", i, j);
    return;
}
```
12. printf("%zu") # printf 的语法 %[parameter][flags][width][.precision][length]type，这里 z 是 length 字段，表示 size_t

### tmux 代码阅读笔记
1.int flock(int fd, int operation);

### Misc 库函数或者系统调用 memo 记录
1. ftruncate 裁剪文件时，文件的位置偏移并不会发生变化，所以执行完 ftruncate 函数后或者前需要手动修改下文件的偏移 lseek
2. socket 在执行 bind 的时候，如果传递的端口号是 0，那么绑定的是随机端口，在绑定之前，即 socket 只是创建的时候，端口默认是 0


### 数据结构
1. 二分查找（必须是有序排列）
2. 树，除了跟结点之外，其他结点的父结点只有一个，一颗 N 个结点的树有 N - 1 条边
	1. 结点的度（degree）：结点的子树的个数
	2. 树的度：树的所有结点中最大的度数
	3. 叶结点：度为 0  的结点
	4. 父结点：有子树的结点是其子树的父结点
	5. 子结点：
	6. 兄弟结点（sibling）：
	7. 路径和路径长度：路径包含边的个数
	8. 祖先结点（ancestor）：
	9. 子孙结点（descendant）：
	10. 结点的层次（level）：根结点在 1 层，其他任一结点的层数是其父结点层数加 1
	11. 树的深度（depth）：树中所有结点中最大层次的树深度

### 操作符优先级
|级别（由高到低）|操作符（使用空格分隔）|结合性|
|---|:---|:---|
|1|() [] -> .|由左向右|
|2|++ -- + - ! ~ (type) * & sizeof|由右向左|
|3|* / %|由左向右|
|4|+ -|由左向右|
|5|<< >>|由左向右|
|6|< <= > >=|由左向右|
|7|== !=|由左向右|
|8|&|由左向右|
|9|^|由左向右|
|10|\||由左向右|
|11|&&|由左向右|
|12|\|\||由左向右|
|13|?:|由右向左|
|14|= += -= *= /= %= &= ^= \|= <<= >>=|由右向左|
|15|,|由左向右|

### gcc 汇编部分内容
* .size 指令
	* .size name, expression // 设置 name 这个符号的大小,这个指令一般用来设置函数符号大小
* .syntax unified // 可以同时使用 arm 和 thumb 指令集???

### [hello-algo](https://github.com/krahets/hello-algo) 阅读笔记

#### 计算复杂度(算法运行追求,运行的快,内存占用小)

* 时间效率:时间复杂度(Time Complexity),算法运行速度快慢,时间复杂度分析采取了不同的做法,统计的不是算法运行时间,而是算法运行时间随着数据量变大时的**增长趋势**.

  * 常数阶:算法运行时间不随着输入数据的增长而增大
  * 线性阶:算法运行时间随着输入数据的增大而线性增大
  
* 在计算时间复杂度时,有如下偷懒技巧:
  1. 跳过数量和 n 无关的操作

  2. 省略所有系数
  
  3. 循环嵌套时使用乘法,总操作数量是外层循环和内存循环的积,每层循环仍然使用1和2技巧
  
  ```c++
  void algorithm(int n) {
    int a = 1;  // +0（技巧 1）
    a = a + n;  // +0（技巧 1）
    // +n（技巧 2）
    for (int i = 0; i < 5 * n + 1; i++) {
        cout << 0 << endl;
    }
    // +n*n（技巧 3）
    for (int i = 0; i < 2 * n; i++) {
        for (int j = 0; j < n + 1; j++) {
            cout << 0 << endl;
        }
    }
	}
  // 结论:上述算法的复杂度是 O(n*n),即平方阶
  ```
  
* 空间效率:空间复杂度(Space Complexity),占用的内存空间大小,可以分为如下几种类型:

  * 输入空间:存储算法的输入数据
  * 暂存空间:存储算法的变量,对象,函数上下文等数据
    * 暂存数据,保存算法运行中的各种常量,变量和对象
    * 栈帧空间,保存调用函数的上下文数据
    * 指令空间,保存编译后的程序指令,在实际统计中一般忽略不记
  * 输出空间:存储算法的输出数据
  
  实际测试复杂度时存在一定的局限性,一般采用估算的方法.通常情况下,空间复杂度的计算范围是:暂存空间和输出空间.并且,空间复杂度,一般只关注"最差空间复杂度"
  
* 物理结构主要有两种:连续的数组和离散的链表.所有数据结构都是由数组或链表,或者兼而有之.

* 哈希函数用来建立 key 和索引之间的映射关系

* 哈希表中存储元素数据结构被称为**Bucket 桶**, 底层实现可能是数组,二叉树(红黑树),链表,或是他们的组合. 
    * 哈希函数是用来建立 key 和索引之间的映射关系.
    * 哈希冲突现象是,不同的 key 值经过哈希函数后结果是一样的,理想情况,hash函数应该为每一个输入产生唯一的输出.因为哈希函数的输入空间往往比输出空间大,所以不可避免会产生哈希冲突的现象.虽然理论上哈希冲突不可避免,但仍然可以在数据结构层面环节哈希冲突带来的负面影响,尽量保证增删改查的效率.常见的解决哈希冲突的方法有:
      * 链式地址:在原始hash表中,一个桶地址只能存储一个元素(即键值对).考虑将桶地址内的单个元素转换为一个链表,将所有冲突元素都存储在一个链表中,此时哈希表操作方法为:
        * 链表引入
          * 查询元素:先将key输入到哈希函数,得到桶地址(访问链表头),再遍历链表来确定对应的 value
          * 添加元素:先通过hash函数访问链表头部,再将元素直接添加到链表头部
          * 删除元素:同样先访问链表头部,再遍历链表查找对应元素,删除即可
        * 二叉树引入(引入链表虽然解决了hash冲突,查询效率也随之降低,因为需要线性遍历来确认对应元素.为了缓解此问题,当某个桶地址内的链表太长时,可以将链表转化为**平衡二叉搜索树**,将时间复杂度降低)
      * 开放寻址:不引入新的数据结构,而是通过向后探测来解决哈希冲突,根据探测方法不同,分为:线性探测,平方探测,多次哈希
    
* 二叉树(Binary Tree)是一种非线性数据结构,代表着祖先和后代的派生关系,体现着"一分为二"的分治逻辑.类似链表,二叉树也是以结点为单位存储的,结点包含**值**和**两个指针**.

    * 根结点(root node):二叉树最顶层的结点,其没有父结点
    * 叶结点(leaf node):没有子结点的结点,其两个指针都指向null
    * 结点所处的层(level):从顶到底依次增加,根节点所处层为 1
    * 结点度(degree):结点的子结点数量,二叉树中,树的范围是0,1,2
    * 边(edge):连接两个结点的边,即结点指针
    * 二叉树高度:二叉树中根节点到最远叶结点走过边的数量
    * 结点深度(deepth):根节点到该结点走过边的数量
    * 结点高度(height):最远叶结点到该结点走过边的数量
    
* 常见二叉树的种类

    * 完美二叉树(perfect binary tree),又称为满二叉树,所有层的结点都被填充
    * 完全二叉树(complete binary tree),只有最底层的结点未被填满,且最底层结点尽量靠左填充
    * 完满二叉树(full binary tree),除了叶结点外,其他结点都有两个子结点,结点的度是0或者2
    * 平衡二叉树(balanced binary tree),任意结点的左子树和右子树的高度之差的绝对值<=1
    
* 二叉树的退化

    * 当二叉树的每层结点都被填满时,达到完美二叉树,完美二叉树是二叉树的"最佳状态",可以发挥二叉树"分治"的优势
    * 左右结点都偏向一端时,二叉树退化为链表,链表则是另一个极端,各项操作都变为线性操作,时间复杂度退化为O(n)
    
* 二叉树的遍历:非线性数据结构的遍历比线性更加复杂,往往需要使用搜索算法实现,常见的二叉树搜索算法:层序遍历,前序遍历,中序遍历,后序遍历

    * 层序遍历:一层一层,从左向右,本质是广度优先,体现着一种,一圈一圈向外的层进遍历方式,广度优先一般借助"队列"实现,队列的规则是先进先出
    * 前,中,后序遍历皆是"深度优先遍历",体现着一种先走到尽头再回头继续的回溯遍历方式,前,中,后序都是以根节点为参考的,并且,左右节点都是先左后右
        * 前序遍历:根节点->左子树->右子树
        * 中序遍历:左子树->根节点->右子树 **常见**
        * 后序遍历:左子树->右子树->根节点
    
* 二叉搜索树(binary search tree),需要满足两个条件:

    * 针对根节点,左子树所有节点的值<根节点<右子树所有节点的值

    * 任意节点的的左子树和右子树也是二叉搜索树,即满足条件1

    * 二叉搜索树不允许出现重复节点
----
* AVL 树(即是二叉搜索树,也是平衡二叉树),同时满足这两种二叉树的所有性质,因此被称为"平衡二叉搜索树"	
* 递归:基线条件,递归条件

    * 一般地,递归只是让解决方案更清晰,并没有性能上的优势.实际上,在有些情况下,使用循环的性能更好
    * 每个递归函数都有两个部分:基线条件(base case),递归条件(recursive case)
        * 递归条件,指的是函数调用自己
        * 基线条件,指的是函数不再调用自己,从而避免无限循环
----
* 分而治之（divide and conquer，D&C）,是一种通用的问题解决方法,也是一种著名的递归式问题解决方法,步骤:

    * 找出基线条件,这种条件必须尽可能简单
    * 不断将问题分解(或者说缩小规模),直到符合基线条件
----
* 散列表
    * 散列函数,无论你给它什么数据,都返回一个数字,此外散列函数还需要满足:
      1. 必须有一致性,给定相同的输入,输出必须保持一致,保持一样
      2. 理想情况,给定不同的输入,输出也不同,否则的话,如果不同的输入对应同一个输出,这种现象叫做哈希冲突
    * 散列表使用数组来存储数据,因此其获取元素的速度和数组一样快
    * python 使用字典 dict 创建散列表
    * 散列表也是 DNS 解析的方式之一
        * 填装因子: 散列表包含的元素 / 位置总数, 一般地,如果填装因子 > 0.7,就要调整散列表的长度
        * 散列函数: 比如 SHA 函数就是良好的散列函数, 良好的散列函数让数组中的值呈现均匀分布,糟糕的散列函数导致大量冲突
    * 散列表是无序的
* 狄克斯特拉算法
    * Dijikstra's algorithm : 在传统图的基础上,给每条边引入了权重的概念
* 贪婪算法,简单易行,在某些场景下,完美是优秀的敌人,有时候,你只需找到一个大致可以解决问题的方法,此时可以选择贪婪算法,因为他们实现起来容易,得到的结果和正确的又比较相近
* NP 完全问题,难解决,很难编出来可以快速解决这类问题的算法,比如旅行商问题和集合覆盖问题,针对 NP 完全问题,最佳的做法是找到近似算法,贪婪算法容易实现,运行速度快,是不错的近似算法
* 动态规划从小问题着手,逐步解决大问题

### 图论[入门](ttps://zhuanlan.zhihu.com/p/3444252)

---

- 节点被称为 V(vertex)， 路径被称为 E(edge)
- 节点边缘的数量被称为自由度
- 有限无向图 G(V,E) 的 Euler 路径是指 G 的每一个边都只出现一次的路径。如果 G 有一条 Euler 路径，它就被称之 Euler 图。
- 定理：有且仅有两个确定的节点存在奇数自由度，其它的节点都有偶数自由度，那么该有限无向图为 Euler 图。
- 有限图（Finite graph）是指有限数量的边和节点的图。
- 二叉搜索树（BST），任意节点的键值必须比它左边子树的键值要大，比右边子树上的键值要小。
- 树的高度是最长路径上节点的数量
- 算法一般用 O 表示，O(xxx) 表示算法复杂度
- 邻接矩阵（Adjacency matrix）可以用来描述无向图，邻接矩阵占用很多额外的空间，为了节省空间，可以用邻接列表（哈希表->列表(或者vector)）
- DFS（深度优先）， BFS（广度优先）
